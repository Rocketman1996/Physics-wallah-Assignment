{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTUqMZfxmEaHLof1ol+6HI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rocketman1996/Physics-wallah-Assignment/blob/main/Web_Scrapping_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
      ],
      "metadata": {
        "id": "uHYdL9UOQgB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Web scrapping is basically the process of data extracting from a web page or website. It involves programmatically accessing a web page, storing a web page and parsing it into html and then extracting the desired content fro it.\n",
        "\n",
        "It is used for various reasons -\n",
        "\n",
        "**1 Data Collection and Analysis**\n",
        "\n",
        "* financial data analysis - Financial institutions scrape financial news\n",
        "  websites and stock market data for real-time information that can inform investment decisions.\n",
        "\n",
        "* social media data analysis - Researchers and businesses scrape social media\n",
        "  platforms to analyze public sentiment, track brand mentions, and gather user-generated content.\n",
        "\n",
        "* market research - Companies use web scraping to gather data on\n",
        "  competitors' products and prices, market trends, and consumer sentiments.\n",
        "\n",
        "**2 Content Aggregation**\n",
        "**3 Business Automation**\n",
        "* In both the cases companies scrap the required data from various data sources like websites, blog-posts etc to watch over their competitions, market research and for syndicating."
      ],
      "metadata": {
        "id": "eXg66sBPRVnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What are the different methods used for Web Scraping?"
      ],
      "metadata": {
        "id": "dajSrzQVWBQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Using Browser Extensions:\n",
        "\n",
        "There are browser extensions like \"Web Scraper\" for Chrome or \"Beautiful Soup\" for Firefox that can assist in scraping data from web pages.\n",
        "\n",
        "3. Writing Custom Scripts:\n",
        "\n",
        "Most web scraping tasks involve writing custom scripts in programming languages like Python, JavaScript, or Ruby.\n",
        "Python, with libraries such as BeautifulSoup and Scrapy, is particularly popular for web scraping due to its simplicity and powerful scraping libraries.\n",
        "\n",
        "4. Headless browsers\n",
        "\n",
        "5. Web Scraping Frameworks\n",
        "\n",
        "Web scraping frameworks like Scrapy (for Python) provide a structured way to build and run web scraping projects.\n",
        "They offer features for handling request/response cycles, data parsing, and data storage.\n",
        "\n",
        "6. API Access:\n",
        "\n",
        "Some websites offer Application Programming Interfaces (APIs) that allow users to access data in a structured and legal manner. APIs are a preferred method when available."
      ],
      "metadata": {
        "id": "oDKJEIQtWDwl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. What is Beautiful Soup? Why is it used?"
      ],
      "metadata": {
        "id": "YrhMwz9LbtG3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BeautifulSoup is a Python library used for data scraping.\n",
        "\n",
        "it is used because it provides tools for parsing html and xml file, find the details inside, beautifying the website content in a good format. It has a good integration with the request library as well."
      ],
      "metadata": {
        "id": "HPFWCzcAbvNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Why is flask used in this Web Scraping project?"
      ],
      "metadata": {
        "id": "ZdqxAdMzcpT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flask is used in web scraping projects because:\n",
        "\n",
        "Web Interface: It helps create a user-friendly web interface for users to interact with the scraping tool.\n",
        "\n",
        "APIs: It enables the scraping functionality to be accessed by other programs through APIs.\n",
        "\n",
        "Integration: Flask easily works with web scraping libraries and tools.\n",
        "\n",
        "Customization: It allows tailoring the project to specific needs and adding custom logic.\n",
        "\n",
        "Scalability: It's lightweight for small projects but can grow as the project evolves.\n",
        "\n",
        "Community Support: Flask has an active developer community with resources and extensions.\n",
        "\n",
        "Example Use: It's used for creating web forms to input URLs, initiating scraping, and presenting results to users."
      ],
      "metadata": {
        "id": "64SQCw2bcsMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
      ],
      "metadata": {
        "id": "DSk3aVPbeBwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** 1. Elastic Beanstalk**\n",
        "- it works as a PaaS (platfor as a service). it is a platformfor where we can deploy and manage web application.\n",
        "\n",
        "** 2. Code Pipeline**\n",
        "- This code pipe line is work on CI/CD (continous integration and continous deployment) it is useful for automatic testing and deployment as soon as we make changes and commit inside the github where our files saved.\n"
      ],
      "metadata": {
        "id": "xrMM_--DeCVa"
      }
    }
  ]
}